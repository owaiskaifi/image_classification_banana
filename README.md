# information about files:

  convert_pytorch_model.py: converts the given model to onix
  
  server.py:main serverfile which will be used
  
  test.py: test inference code 
  
  test_banana.py : file used to test banana deployment
  
  




# üçå Banana Serverless

This repo gives a framework to serve ML models in production using simple HTTP servers.

# Quickstart
**[Follow the quickstart guide in Banana's documentation to use this repo](https://docs.banana.dev/banana-docs/quickstart).** 

*(choose "GitHub Repository" deployment method)*

<br>

# Helpful Links
Understand the üçå [Serverless framework](https://docs.banana.dev/banana-docs/core-concepts/inference-server/serverless-framework) and functionality of each file within it.

Generalize this framework to [deploy anything on Banana](https://docs.banana.dev/banana-docs/resources/how-to-serve-anything-on-banana).

<br>

## Use Banana for scale.
